{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will explore how importance scores from three different methods compare on simulated data.\n",
    "\n",
    "The simulated data was as follows:\n",
    "- 1/4th sequences with 1-3 instances of a GATA_disc1 motif embedded (see http://compbio.mit.edu/encode-motifs/ for the PWM); these were labelled 0,1,0\n",
    "- 1/4rd sequences with 1-3 instances of a TAL1_known1 motif embedded; these were labelled 0,0,1\n",
    "- 1/4rd sequences with BOTH 1-3 instances of a GATA_disc1 motif AND 1-3 instances of a TAL1_known1 motif; these were labelled 1,1,1\n",
    "- 1/4rd sequences with no motifs embedded; these were labelled 0,0,0\n",
    "\n",
    "Scores for all three tasks for sequences that contain both TAL1_known1 and GATA_disc1 motifs are analyzed in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate data to analyze. Let's make datasets with the same distribution of motifs as the data that the model was trained on (the model was not trained on this exact data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: made 10 attemps at trying to embed TAL1_known1-TTGACCAGATGTTAAA in region of length 200 with 52.0 occupied sites\r\n"
     ]
    }
   ],
   "source": [
    "#Generate the data. Will install the simdna package if necessary.\n",
    "try:\n",
    "    import simdna\n",
    "except ImportError, e:\n",
    "    print(\"installing simdna package\")\n",
    "    !pip install git+git://github.com/kundajelab/simdna.git\n",
    "\n",
    "#This will produce a warning about embedding a TAL1_known1 motif, which is normal\n",
    "!./generate_data.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import simdna.synthetic as synthetic\n",
    "tal_gata_filename = \"DensityEmbedding_prefix-talgata_motifs-GATA_disc1+TAL1_known1_min-1_max-3_mean-2_zeroProb-0_seqLength-200_numSeqs-1000.simdata.gz\"\n",
    "#read in the data\n",
    "tal_gata_data = synthetic.read_simdata_file(tal_gata_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the keras model and convert the models to the importance-scoring format. We will compare methods of deeplift, gradient\\*input and guided backprop\\*input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import deeplift\n",
    "import deeplift.conversion.keras_conversion as kc\n",
    "import numpy as np\n",
    "from deeplift.blobs import NonlinearMxtsMode\n",
    "\n",
    "#load the keras model\n",
    "#at the time of writing, this uses keras 0.3 and theano dimension ordering\n",
    "keras_model_weights = \"record_2_model_v0CG1_modelWeights.h5\"\n",
    "keras_model_yaml = \"record_2_model_v0CG1_modelYaml.yaml\"\n",
    "keras_model = kc.load_keras_model(weights=keras_model_weights,\n",
    "                                  yaml=keras_model_yaml)\n",
    "\n",
    "#make various kinds of importance scoring models\n",
    "deeplift_model, grad_model, guided_backprop_model, guided_backprop_deeplift_model =\\\n",
    "    [kc.convert_sequential_model(\n",
    "        model=keras_model,\n",
    "        nonlinear_mxts_mode=nonlinear_mxts_mode) for nonlinear_mxts_mode in\n",
    "        [NonlinearMxtsMode.DeepLIFT,\n",
    "         NonlinearMxtsMode.Gradient,\n",
    "         NonlinearMxtsMode.GuidedBackprop,\n",
    "         NonlinearMxtsMode.GuidedBackpropDeepLIFT]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#install the avutils package if it isn't installed\n",
    "try:\n",
    "    import avutils\n",
    "except ImportError, e:\n",
    "    print(\"installing avutils package\")\n",
    "    !pip install git+git://github.com/kundajelab/avutils.git\n",
    "\n",
    "import avutils\n",
    "import avutils.util\n",
    "\n",
    "#get one-hot encoded sequence for the tal_gata data\n",
    "tal_gata_onehot = np.array([avutils.util.seq_to_one_hot(seq) for seq in tal_gata_data.sequences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check that the conversion happened correctly by making sure both the original keras model and the converted models are giving the same predictions (this is not strictly necessary for computing importance scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure predictions are the same as the original model\n",
    "from deeplift.util import compile_func\n",
    "deeplift_prediction_func = compile_func([deeplift_model.get_layers()[0].get_activation_vars()],\n",
    "                                        deeplift_model.get_layers()[-1].get_activation_vars())\n",
    "original_model_predictions = keras_model.predict(tal_gata_onehot, batch_size=200)\n",
    "converted_model_predictions = deeplift.util.run_function_in_batches(\n",
    "                                input_data_list=[tal_gata_onehot],\n",
    "                                func=deeplift_prediction_func,\n",
    "                                batch_size=200,\n",
    "                                progress_update=None)\n",
    "assert np.max(np.array(converted_model_predictions)-np.array(original_model_predictions)) < 10**-5\n",
    "tal_gata_predictions = converted_model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the predictions by confidence, for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#taldata predictions sorted by confidence\n",
    "tal_gata_predictions_sorted = sorted(enumerate(tal_gata_predictions), key=lambda x: -x[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the importance scores using the three different methods for all three tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#set the reference to something with gc content of background\n",
    "reference = np.array([0.27, 0.23, 0.23, 0.27])[None,None,:]\n",
    "\n",
    "#compute the importance scores on the sequences\n",
    "deeplift_func, grad_times_inp_func, guided_backprop_func, guided_backprop_deeplift_func =\\\n",
    "    [model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\n",
    "     for model in [deeplift_model, grad_model, guided_backprop_model, guided_backprop_deeplift_model]]\n",
    "\n",
    "from collections import OrderedDict\n",
    "method_to_task_to_scores = OrderedDict()\n",
    "for method_name, score_func in [('deeplift', deeplift_func),\n",
    "                               ('grad_times_inp', grad_times_inp_func),\n",
    "                               ('guided_backprop_times_inp', guided_backprop_func),\n",
    "                               ('guided_backprop_deeplift_times_inp', guided_backprop_deeplift_func)]:\n",
    "    method_to_task_to_scores[method_name] = {}\n",
    "    for task_idx in [0,1,2]:\n",
    "        scores = np.array(score_func(\n",
    "                    task_idx=task_idx,\n",
    "                    input_data_list=[tal_gata_onehot],\n",
    "                    input_references_list=[reference],\n",
    "                    batch_size=200,\n",
    "                    progress_update=None))\n",
    "        assert scores.shape[-1]==4\n",
    "        scores = np.sum(scores, axis=-1) #sum over each position\n",
    "        method_to_task_to_scores[method_name][task_idx] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the coordinates of the embedded motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motif_locations = {'GATA_disc1':[], 'TAL1_known1':[]}\n",
    "for embeddings in tal_gata_data.embeddings:\n",
    "    for motif in motif_locations:\n",
    "        motif_locations[motif].append([])\n",
    "    for embedding in embeddings:\n",
    "        motif_locations[embedding.what.getDescription()][-1]\\\n",
    "                       .append((embedding.startPos, embedding.startPos+len(embedding.what)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the scores at the sequence predicted most confidently. Cyan boxes indicate the ground-truth locations of the inserted TAL1_known1 motifs, red boxes indicate the ground-truth locations of the inserted GATA_disc1 motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualize scores + ground-truth locations of motifs\n",
    "%matplotlib inline\n",
    "from deeplift.visualization import viz_sequence\n",
    "reload(viz_sequence)\n",
    "\n",
    "sorted_idx = 0\n",
    "idx = tal_gata_predictions_sorted[sorted_idx][0]\n",
    "\n",
    "for method_name in method_to_task_to_scores:\n",
    "    scores = method_to_task_to_scores[method_name][0]\n",
    "    scores_for_idx = scores[idx]\n",
    "    original_onehot = tal_gata_onehot[idx]\n",
    "    scores_for_idx = original_onehot*scores_for_idx[:,None]\n",
    "    print(method_name)\n",
    "    highlight = {'red':motif_locations['GATA_disc1'][idx],\n",
    "                 'cyan':motif_locations['TAL1_known1'][idx]}\n",
    "    viz_sequence.plot_weights(scores_for_idx, subticks_frequency=10, highlight=highlight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
